import pandas as pd
import numpy as np
import xgboost as xgb
import re
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import LabelEncoder, StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“ä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class MaternalDataPreprocessor:
    """æ¯ä½“æ•°æ®é¢„å¤„ç†ç±»"""

    def __init__(self):
        self.label_encoders = {}
        self.scaler = StandardScaler()

    def convert_gestational_week(self, week_str):
        """å°† 'Xw+Y' æ ¼å¼çš„å­•å‘¨å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼ï¼ˆä»¥å‘¨ä¸ºå•ä½ï¼‰"""
        if pd.isna(week_str):
            return np.nan
        if isinstance(week_str, (int, float)):
            return float(week_str)
        if isinstance(week_str, str):
            # åŒ¹é… "11w+6" æˆ– "11w" æˆ– "11" æ ¼å¼
            pattern = r'(\d+)w?(?:\+(\d+))?'
            match = re.match(pattern, week_str.strip())
            if match:
                weeks = int(match.group(1))
                days = int(match.group(2)) if match.group(2) else 0
                return weeks + days / 7.0
        return np.nan

    def clean_categorical_data(self, series, column_name):
        """æ¸…ç†åˆ†ç±»æ•°æ®"""
        if series.dtype == 'object':
            # å¸¸è§çš„åˆ†ç±»æ˜ å°„
            mapping_dict = {
                'èƒå„¿æ˜¯å¦å¥åº·': {'æ˜¯': 1, 'å¥åº·': 1, 'æ­£å¸¸': 1, 'å¦': 0, 'å¼‚å¸¸': 0, 'ä¸å¥åº·': 0},
                'IVFå¦Šå¨ ': {'æ˜¯': 1, 'IVFå¦Šå¨ ': 1, 'IVF': 1, 'å¦': 0, 'è‡ªç„¶å—å­•': 0, 'è‡ªç„¶': 0},
                'æŸ“è‰²ä½“çš„éæ•´å€ä½“': {'æ­£å¸¸': 0, 'å¼‚å¸¸': 1, 'æ˜¯': 1, 'å¦': 0}
            }

            if column_name in mapping_dict:
                return series.map(mapping_dict[column_name])
            else:
                # å¯¹äºå…¶ä»–åˆ†ç±»å˜é‡ï¼Œä½¿ç”¨LabelEncoder
                if column_name not in self.label_encoders:
                    self.label_encoders[column_name] = LabelEncoder()
                    # å¤„ç†ç¼ºå¤±å€¼
                    non_null_values = series.dropna()
                    if len(non_null_values) > 0:
                        self.label_encoders[column_name].fit(non_null_values)
                        encoded = series.copy()
                        mask = series.notna()
                        encoded[mask] = self.label_encoders[column_name].transform(series[mask])
                        return pd.to_numeric(encoded, errors='coerce')
                return pd.to_numeric(series, errors='coerce')
        return pd.to_numeric(series, errors='coerce')

    def preprocess_data(self, df):
        """ä¸»è¦çš„æ•°æ®é¢„å¤„ç†å‡½æ•°"""
        df_processed = df.copy()

        # 1. å¤„ç†æ£€æµ‹å­•å‘¨
        print("å¤„ç†æ£€æµ‹å­•å‘¨...")
        df_processed['æ£€æµ‹å­•å‘¨_æ•°å€¼'] = df_processed['æ£€æµ‹å­•å‘¨'].apply(self.convert_gestational_week)

        # 2. å¤„ç†æ‰€æœ‰åˆ—çš„æ•°æ®ç±»å‹
        print("æ¸…ç†å’Œè½¬æ¢æ•°æ®ç±»å‹...")
        for col in df_processed.columns:
            if col not in ['åºå·', 'å­•å¦‡ä»£ç ', 'æœ«æ¬¡æœˆç»', 'æ£€æµ‹æ—¥æœŸ']:  # è·³è¿‡IDå’Œæ—¥æœŸåˆ—
                print(f"  å¤„ç†åˆ—: {col}")
                print(f"    åŸå§‹æ•°æ®ç±»å‹: {df_processed[col].dtype}")
                print(f"    å”¯ä¸€å€¼ç¤ºä¾‹: {df_processed[col].unique()[:5]}")

                try:
                    df_processed[col] = self.clean_categorical_data(df_processed[col], col)
                    print(f"    è½¬æ¢åæ•°æ®ç±»å‹: {df_processed[col].dtype}")
                except Exception as e:
                    print(f"    è­¦å‘Šï¼šå¤„ç†åˆ— '{col}' æ—¶å‡ºé”™: {e}")
                    # å¦‚æœå‡ºé”™ï¼Œç›´æ¥å°è¯•æ•°å€¼è½¬æ¢
                    df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')

        return df_processed

def explore_data(df, target_variable):
    """æ•°æ®æ¢ç´¢æ€§åˆ†æï¼ˆä¸åŒ…å«ç»˜å›¾ï¼‰"""
    print("=== æ•°æ®æ¢ç´¢æ€§åˆ†æ ===")
    print(f"æ•°æ®é›†å½¢çŠ¶: {df.shape}")
    print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_data = df.isnull().sum()
    missing_percent = (missing_data / len(df)) * 100
    missing_df = pd.DataFrame({
        'ç¼ºå¤±æ•°é‡': missing_data,
        'ç¼ºå¤±ç™¾åˆ†æ¯”': missing_percent
    }).sort_values('ç¼ºå¤±ç™¾åˆ†æ¯”', ascending=False)
    print(missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0])

    # ç›®æ ‡å˜é‡ç»Ÿè®¡
    print(f"\nç›®æ ‡å˜é‡ '{target_variable}' ç»Ÿè®¡:")
    print(df[target_variable].describe())
    
    # è¿”å›ç”¨äºåç»­ç»˜å›¾çš„æ•°æ®
    return {
        'missing_df': missing_df,
        'target_stats': df[target_variable].describe(),
        'target_data': df[target_variable].dropna()
    }

def train_and_evaluate_model(X_train, X_val, X_test, y_train, y_val, y_test, use_grid_search=False):
    """è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹ - ä¿®æ­£ç‰ˆæœ¬"""
    
    print(f"æ•°æ®åˆ’åˆ†: è®­ç»ƒé›†{X_train.shape}, éªŒè¯é›†{X_val.shape}, æµ‹è¯•é›†{X_test.shape}")
    
    if use_grid_search:
        print("æ­£åœ¨è¿›è¡Œè¶…å‚æ•°è°ƒä¼˜...")
        param_grid = {
            'n_estimators': [500, 1000, 1500],
            'learning_rate': [0.01, 0.05, 0.1],
            'max_depth': [3, 5, 7],
            'subsample': [0.8, 0.9],
            'colsample_bytree': [0.8, 0.9]
        }

        xgb_regressor = xgb.XGBRegressor(
            objective='reg:squarederror',
            random_state=42,
            n_jobs=-1,
            eval_metric='rmse'
        )

        # ä½¿ç”¨è®­ç»ƒé›†+éªŒè¯é›†è¿›è¡Œç½‘æ ¼æœç´¢
        X_train_val = pd.concat([X_train, X_val])
        y_train_val = pd.concat([y_train, y_val])
        
        grid_search = GridSearchCV(
            xgb_regressor,
            param_grid,
            cv=5,
            scoring='r2',
            n_jobs=-1,
            verbose=2
        )

        import time
        start_time = time.time()
        print("å¼€å§‹ç½‘æ ¼æœç´¢...")
        grid_search.fit(X_train_val, y_train_val)
        end_time = time.time()
        
        best_model = grid_search.best_estimator_
        print(f"ç½‘æ ¼æœç´¢è€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
        print(f"æœ€ä½³CVå¾—åˆ†: {grid_search.best_score_:.4f}")
        
    else:
        print("ä½¿ç”¨å›ºå®šå‚æ•°è®­ç»ƒ...")
        best_model = xgb.XGBRegressor(
            objective='reg:squarederror',
            n_estimators=2000,  
            learning_rate=0.03,  
            max_depth=6,         
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            n_jobs=-1,
            eval_metric='rmse'
        )

        import time
        start_time = time.time()
        print("å¼€å§‹è®­ç»ƒ...")
        
        try:
            from xgboost.callback import EarlyStopping
            
            best_model.fit(
                X_train, y_train,
                eval_set=[(X_train, y_train), (X_val, y_val)],  # ä½¿ç”¨éªŒè¯é›†è¿›è¡Œæ—©åœ
                eval_names=['train', 'validation'],
                callbacks=[EarlyStopping(rounds=200, save_best=True)],
                verbose=50
            )
            
            end_time = time.time()
            print(f"è®­ç»ƒå®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"å®é™…è®­ç»ƒè½®æ•°: {best_model.best_iteration}")
            
            # éªŒè¯é›†æ€§èƒ½ï¼ˆè®­ç»ƒè¿‡ç¨‹ä¸­çš„ç›‘æ§ï¼‰
            val_pred = best_model.predict(X_val)
            val_r2 = r2_score(y_val, val_pred)
            print(f"éªŒè¯é›†RÂ² (è®­ç»ƒè¿‡ç¨‹ç›‘æ§): {val_r2:.4f}")
            
        except (ImportError, TypeError):
            print("ä½¿ç”¨å…¼å®¹æ¨¡å¼ï¼Œè®­ç»ƒå…¨éƒ¨è½®æ•°...")
            best_model.fit(X_train, y_train)
            end_time = time.time()
            print(f"è®­ç»ƒå®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f}ç§’")
            print(f"è®­ç»ƒäº†å…¨éƒ¨ {best_model.n_estimators} è½®")

    return best_model

def evaluate_model_performance(model, X_train, X_val, X_test, y_train, y_val, y_test):
    """è¯¦ç»†çš„æ¨¡å‹æ€§èƒ½è¯„ä¼°"""
    print("\n=== è¯¦ç»†æ¨¡å‹æ€§èƒ½è¯„ä¼° ===")
    
    # åˆ†åˆ«é¢„æµ‹ä¸‰ä¸ªæ•°æ®é›†
    y_train_pred = model.predict(X_train)
    y_val_pred = model.predict(X_val)
    y_test_pred = model.predict(X_test)
    
    # è®¡ç®—å„æ•°æ®é›†çš„è¯„ä¼°æŒ‡æ ‡
    train_r2 = r2_score(y_train, y_train_pred)
    train_mae = mean_absolute_error(y_train, y_train_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    
    val_r2 = r2_score(y_val, y_val_pred)
    val_mae = mean_absolute_error(y_val, y_val_pred)
    val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))
    
    test_r2 = r2_score(y_test, y_test_pred)
    test_mae = mean_absolute_error(y_test, y_test_pred)
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    
    # æ‰“å°ç»“æœ
    print("è®­ç»ƒé›†æ€§èƒ½:")
    print(f"  RÂ²: {train_r2:.4f}")
    print(f"  MAE: {train_mae:.4f}")
    print(f"  RMSE: {train_rmse:.4f}")
    
    print("\néªŒè¯é›†æ€§èƒ½:")
    print(f"  RÂ²: {val_r2:.4f}")
    print(f"  MAE: {val_mae:.4f}")
    print(f"  RMSE: {val_rmse:.4f}")
    
    print("\næµ‹è¯•é›†æ€§èƒ½ (æœ€ç»ˆè¯„ä¼°):")
    print(f"  RÂ²: {test_r2:.4f}")
    print(f"  MAE: {test_mae:.4f}")
    print(f"  RMSE: {test_rmse:.4f}")
    
    # è¿‡æ‹Ÿåˆæ£€æŸ¥
    train_val_diff = train_r2 - val_r2
    val_test_diff = val_r2 - test_r2
    
    print(f"\næ€§èƒ½å·®å¼‚åˆ†æ:")
    print(f"  è®­ç»ƒé›† - éªŒè¯é›† RÂ²å·®å¼‚: {train_val_diff:.4f}")
    print(f"  éªŒè¯é›† - æµ‹è¯•é›† RÂ²å·®å¼‚: {val_test_diff:.4f}")
    
    if train_val_diff > 0.1:
        print("  âš ï¸  è®­ç»ƒé›†å’ŒéªŒè¯é›†å·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
    elif abs(val_test_diff) > 0.05:
        print("  âš ï¸  éªŒè¯é›†å’Œæµ‹è¯•é›†å·®å¼‚è¾ƒå¤§ï¼Œæ¨¡å‹æ³›åŒ–æ€§å¯èƒ½ä¸ç¨³å®š")
    else:
        print("  âœ… æ¨¡å‹åœ¨å„æ•°æ®é›†ä¸Šè¡¨ç°ä¸€è‡´ï¼Œæ³›åŒ–æ€§è‰¯å¥½")
    
    return {
        'train': {'r2': train_r2, 'mae': train_mae, 'rmse': train_rmse, 'predictions': y_train_pred},
        'validation': {'r2': val_r2, 'mae': val_mae, 'rmse': val_rmse, 'predictions': y_val_pred},
        'test': {'r2': test_r2, 'mae': test_mae, 'rmse': test_rmse, 'predictions': y_test_pred},
        'y_train': y_train, 'y_val': y_val, 'y_test': y_test,
        'residuals_test': y_test - y_test_pred
    }

def plot_target_distribution(target_data, target_variable):
    """ç»˜åˆ¶ç›®æ ‡å˜é‡åˆ†å¸ƒ"""
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.hist(target_data, bins=30, alpha=0.7, color='skyblue')
    plt.title(f'{target_variable} åˆ†å¸ƒ')
    plt.xlabel(target_variable)
    plt.ylabel('é¢‘æ¬¡')

    plt.subplot(1, 2, 2)
    plt.boxplot(target_data)
    plt.title(f'{target_variable} ç®±çº¿å›¾')
    plt.ylabel(target_variable)

    plt.tight_layout()
    plt.show()

def plot_model_performance(results):
    """ç»˜åˆ¶æ¨¡å‹æ€§èƒ½å›¾"""
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    
    datasets = ['train', 'validation', 'test']
    colors = ['blue', 'orange', 'green']
    
    # ç¬¬ä¸€è¡Œï¼šå®é™…å€¼ vs é¢„æµ‹å€¼
    for i, (dataset, color) in enumerate(zip(datasets, colors)):
        ax = axes[0, i]
        y_true = results[f'y_{dataset}'] if dataset != 'validation' else results['y_val']
        y_pred = results[dataset]['predictions']
        r2 = results[dataset]['r2']
        
        ax.scatter(y_true, y_pred, alpha=0.6, color=color)
        ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)
        ax.set_xlabel('å®é™…å€¼')
        ax.set_ylabel('é¢„æµ‹å€¼')
        ax.set_title(f'{dataset.title()} Set: å®é™…å€¼ vs é¢„æµ‹å€¼ (RÂ² = {r2:.3f})')
    
    # ç¬¬äºŒè¡Œï¼šæ®‹å·®åˆ†æ
    for i, (dataset, color) in enumerate(zip(datasets, colors)):
        ax = axes[1, i]
        y_true = results[f'y_{dataset}'] if dataset != 'validation' else results['y_val']
        y_pred = results[dataset]['predictions']
        residuals = y_true - y_pred
        
        ax.scatter(y_pred, residuals, alpha=0.6, color=color)
        ax.axhline(y=0, color='r', linestyle='--')
        ax.set_xlabel('é¢„æµ‹å€¼')
        ax.set_ylabel('æ®‹å·®')
        ax.set_title(f'{dataset.title()} Set: æ®‹å·®å›¾')
    
    plt.tight_layout()
    plt.show()

def plot_feature_importance(model, feature_names, top_n=15):
    """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§"""
    importance_df = pd.DataFrame({
        'feature': feature_names,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)

    plt.figure(figsize=(12, 8))
    top_features = importance_df.head(top_n)

    bars = plt.barh(range(len(top_features)), top_features['importance'])
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('ç‰¹å¾é‡è¦æ€§')
    plt.title(f'Top {top_n} ç‰¹å¾é‡è¦æ€§')
    plt.gca().invert_yaxis()

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, importance) in enumerate(zip(bars, top_features['importance'])):
        plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2,
                f'{importance:.3f}', va='center', fontsize=9)

    plt.tight_layout()
    plt.show()

    return importance_df

def save_model_and_results(model, results, feature_importance, exploration_data, preprocessor, feature_names, save_dir="model_output"):
    """ä¿å­˜æ¨¡å‹å’Œè®­ç»ƒç»“æœ"""
    import os
    import pickle
    import joblib
    import json
    from datetime import datetime

    # ç”Ÿæˆæ—¶é—´æˆ³
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    save_dir = f"{save_dir}_{timestamp}"
    
    print(f"\n=== ä¿å­˜æ¨¡å‹å’Œç»“æœåˆ° '{save_dir}' ç›®å½• ===")
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
        print(f"åˆ›å»ºç›®å½•: {save_dir}")
    
    
    
    try:
        # 1. ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
        model_path = os.path.join(save_dir, f"xgb_model_{timestamp}.pkl")
        joblib.dump(model, model_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜: {model_path}")
        
        # 2. ä¿å­˜æ•°æ®é¢„å¤„ç†å™¨
        preprocessor_path = os.path.join(save_dir, f"preprocessor_{timestamp}.pkl")
        with open(preprocessor_path, 'wb') as f:
            pickle.dump(preprocessor, f)
        print(f"âœ… é¢„å¤„ç†å™¨å·²ä¿å­˜: {preprocessor_path}")
        
        # 3. ä¿å­˜ç‰¹å¾åç§°
        feature_names_path = os.path.join(save_dir, f"feature_names_{timestamp}.pkl")
        with open(feature_names_path, 'wb') as f:
            pickle.dump(list(feature_names), f)
        print(f"âœ… ç‰¹å¾åç§°å·²ä¿å­˜: {feature_names_path}")
        
        # 4. ä¿å­˜æ¨¡å‹è¯„ä¼°ç»“æœ
        results_to_save = {}
        for dataset in ['train', 'validation', 'test']:
            results_to_save[dataset] = {
                'r2': float(results[dataset]['r2']),
                'mae': float(results[dataset]['mae']),
                'rmse': float(results[dataset]['rmse'])
            }
        
        results_path = os.path.join(save_dir, f"model_results_{timestamp}.json")
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ¨¡å‹è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}")
        
        # 5. ä¿å­˜ç‰¹å¾é‡è¦æ€§
        feature_importance_path = os.path.join(save_dir, f"feature_importance_{timestamp}.csv")
        feature_importance.to_csv(feature_importance_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜: {feature_importance_path}")
        
        # 6. ä¿å­˜é¢„æµ‹ç»“æœ - åˆ†åˆ«ä¿å­˜æ¯ä¸ªæ•°æ®é›†çš„ç»“æœ
        try:
            # åˆ†åˆ«ä¿å­˜è®­ç»ƒé›†é¢„æµ‹ç»“æœ
            train_predictions_df = pd.DataFrame({
                'actual': results['y_train'].values,
                'predicted': results['train']['predictions']
            })
            train_pred_path = os.path.join(save_dir, f"train_predictions_{timestamp}.csv")
            train_predictions_df.to_csv(train_pred_path, index=False, encoding='utf-8-sig')
            
            # åˆ†åˆ«ä¿å­˜éªŒè¯é›†é¢„æµ‹ç»“æœ
            val_predictions_df = pd.DataFrame({
                'actual': results['y_val'].values,
                'predicted': results['validation']['predictions']
            })
            val_pred_path = os.path.join(save_dir, f"val_predictions_{timestamp}.csv")
            val_predictions_df.to_csv(val_pred_path, index=False, encoding='utf-8-sig')
            
            # åˆ†åˆ«ä¿å­˜æµ‹è¯•é›†é¢„æµ‹ç»“æœ
            test_predictions_df = pd.DataFrame({
                'actual': results['y_test'].values,
                'predicted': results['test']['predictions']
            })
            test_pred_path = os.path.join(save_dir, f"test_predictions_{timestamp}.csv")
            test_predictions_df.to_csv(test_pred_path, index=False, encoding='utf-8-sig')
            
            print(f"âœ… è®­ç»ƒé›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {train_pred_path}")
            print(f"âœ… éªŒè¯é›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {val_pred_path}")
            print(f"âœ… æµ‹è¯•é›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {test_pred_path}")
            
        except Exception as pred_error:
            print(f"âŒ ä¿å­˜é¢„æµ‹ç»“æœæ—¶å‡ºé”™: {pred_error}")
            # å¦‚æœä¸Šé¢çš„æ–¹æ³•ä»æœ‰é—®é¢˜ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•
            print("å°è¯•ä½¿ç”¨å¤‡ç”¨ä¿å­˜æ–¹æ³•...")
            
            # å¤‡ç”¨æ–¹æ³•ï¼šé€ä¸ªæ£€æŸ¥å¹¶ä¿å­˜
            for dataset_name, y_actual, y_pred in [
                ('train', results['y_train'], results['train']['predictions']),
                ('val', results['y_val'], results['validation']['predictions']),
                ('test', results['y_test'], results['test']['predictions'])
            ]:
                try:
                    # ç¡®ä¿é•¿åº¦ä¸€è‡´
                    min_len = min(len(y_actual), len(y_pred))
                    df = pd.DataFrame({
                        'actual': y_actual.values[:min_len] if hasattr(y_actual, 'values') else y_actual[:min_len],
                        'predicted': y_pred[:min_len]
                    })
                    path = os.path.join(save_dir, f"{dataset_name}_predictions_{timestamp}.csv")
                    df.to_csv(path, index=False, encoding='utf-8-sig')
                    print(f"âœ… {dataset_name}é›†é¢„æµ‹ç»“æœå·²ä¿å­˜: {path}")
                except Exception as e:
                    print(f"âŒ ä¿å­˜{dataset_name}é›†é¢„æµ‹ç»“æœå¤±è´¥: {e}")
        
        # 7. ä¿å­˜æ¨¡å‹é…ç½®å’Œè®­ç»ƒä¿¡æ¯
        model_info = {
            'timestamp': timestamp,
            'model_type': 'XGBoost Regressor',
            'model_params': model.get_params(),
            'feature_count': len(feature_names),
            'train_samples': len(results['y_train']),
            'validation_samples': len(results['y_val']),
            'test_samples': len(results['y_test']),
            'final_test_r2': float(results['test']['r2']),
            'final_test_rmse': float(results['test']['rmse']),
            'best_features_top5': list(feature_importance.head(5)['feature'].values)
        }
        
        model_info_path = os.path.join(save_dir, f"model_info_{timestamp}.json")
        with open(model_info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, ensure_ascii=False, indent=2)
        print(f"âœ… æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜: {model_info_path}")
        
        # 8. åˆ›å»ºåŠ è½½æ¨¡å‹çš„ç¤ºä¾‹ä»£ç 
        load_example = f"""
# åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹å’Œç›¸å…³æ–‡ä»¶ç¤ºä¾‹ä»£ç 
import joblib
import pickle
import pandas as pd
import json

# åŠ è½½æ¨¡å‹
model = joblib.load('{model_path}')

# åŠ è½½é¢„å¤„ç†å™¨
with open('{preprocessor_path}', 'rb') as f:
    preprocessor = pickle.load(f)

# åŠ è½½ç‰¹å¾åç§°
with open('{feature_names_path}', 'rb') as f:
    feature_names = pickle.load(f)

# åŠ è½½æ¨¡å‹ç»“æœ
with open('{results_path}', 'r', encoding='utf-8') as f:
    results = json.load(f)

# åŠ è½½ç‰¹å¾é‡è¦æ€§
feature_importance = pd.read_csv('{feature_importance_path}', encoding='utf-8-sig')

# åŠ è½½é¢„æµ‹ç»“æœ
train_predictions = pd.read_csv('{os.path.join(save_dir, f"train_predictions_{timestamp}.csv")}', encoding='utf-8-sig')
val_predictions = pd.read_csv('{os.path.join(save_dir, f"val_predictions_{timestamp}.csv")}', encoding='utf-8-sig')
test_predictions = pd.read_csv('{os.path.join(save_dir, f"test_predictions_{timestamp}.csv")}', encoding='utf-8-sig')

# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ (ç¤ºä¾‹)
# new_data = preprocessor.preprocess_data(your_new_dataframe)
# predictions = model.predict(new_data[feature_names])

print("æ¨¡å‹åŠ è½½å®Œæˆï¼")
print(f"æµ‹è¯•é›†RÂ²: {{results['test']['r2']}}")
print(f"æœ€é‡è¦çš„5ä¸ªç‰¹å¾: {{feature_importance.head(5)['feature'].tolist()}}")
"""
        
        load_example_path = os.path.join(save_dir, f"load_model_example_{timestamp}.py")
        with open(load_example_path, 'w', encoding='utf-8') as f:
            f.write(load_example)
        print(f"âœ… æ¨¡å‹åŠ è½½ç¤ºä¾‹ä»£ç å·²ä¿å­˜: {load_example_path}")
        
        print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å·²æˆåŠŸä¿å­˜åˆ° '{save_dir}' ç›®å½•ï¼")
        print(f"ğŸ“ å…±ä¿å­˜äº† 10 ä¸ªæ–‡ä»¶ï¼Œæ—¶é—´æˆ³: {timestamp}")
        
        return {
            'save_directory': save_dir,
            'timestamp': timestamp,
            'saved_files': {
                'model': model_path,
                'preprocessor': preprocessor_path,
                'feature_names': feature_names_path,
                'results': results_path,
                'feature_importance': feature_importance_path,
                'train_predictions': train_pred_path,
                'val_predictions': val_pred_path,
                'test_predictions': test_pred_path,
                'model_info': model_info_path,
                'load_example': load_example_path
            }
        }
        
    except Exception as e:
        print(f"âŒ ä¿å­˜è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return None
    
def main(enable_plotting=False, use_grid_search=False):
    """ä¸»å‡½æ•° - ä¿®æ­£ç‰ˆæœ¬"""
    print("=== YæŸ“è‰²ä½“æµ“åº¦é¢„æµ‹æ¨¡å‹ (ä¿®æ­£ç‰ˆ) ===")

    # 1. æ•°æ®åŠ è½½
    print("\n1. åŠ è½½æ•°æ®...")
    try:
        df = pd.read_excel("maternal_data.xlsx")
        print(f"æˆåŠŸåŠ è½½æ•°æ®ï¼Œå½¢çŠ¶: {df.shape}")
    except FileNotFoundError:
        print("é”™è¯¯ï¼šè¯·ç¡®ä¿ 'maternal_data.xlsx' æ–‡ä»¶ä¸æ­¤è„šæœ¬åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ã€‚")
        return
    except Exception as e:
        print(f"åŠ è½½æ•°æ®æ—¶å‡ºé”™: {e}")
        return

    # 2. æ•°æ®é¢„å¤„ç†
    print("\n2. æ•°æ®é¢„å¤„ç†...")
    preprocessor = MaternalDataPreprocessor()
    df_processed = preprocessor.preprocess_data(df)

    # 3. æ•°æ®æ¢ç´¢ï¼ˆä¸ç»˜å›¾ï¼‰
    TARGET_VARIABLE = 'YæŸ“è‰²ä½“æµ“åº¦'
    exploration_data = explore_data(df_processed, TARGET_VARIABLE)

    # 4. ç‰¹å¾é€‰æ‹©
    print("\n3. ç‰¹å¾é€‰æ‹©...")
    COLUMNS_TO_DROP = [
        'åºå·', 'å­•å¦‡ä»£ç ', 'æœ«æ¬¡æœˆç»', 'æ£€æµ‹æ—¥æœŸ',
        'æ£€æµ‹å­•å‘¨',  # å·²è½¬æ¢ä¸ºæ•°å€¼ç‰ˆæœ¬
    ]

    # ç§»é™¤ä¸å­˜åœ¨çš„åˆ—
    columns_to_drop_filtered = [col for col in COLUMNS_TO_DROP if col in df_processed.columns]

    # ç­›é€‰ç‰¹å¾
    available_columns = [col for col in df_processed.columns if col not in columns_to_drop_filtered + [TARGET_VARIABLE]]
    features = df_processed[available_columns].select_dtypes(include=[np.number])
    target = df_processed[TARGET_VARIABLE]

    print(f"å¯ç”¨ç‰¹å¾: {list(features.columns)}")
    print(f"ç‰¹å¾æ•°é‡: {features.shape[1]}")

    # 5. å¤„ç†ç¼ºå¤±å€¼
    print("\n4. å¤„ç†ç¼ºå¤±å€¼...")
    print("ç‰¹å¾ç¼ºå¤±å€¼æƒ…å†µ:")
    missing_features = features.isnull().sum()[features.isnull().sum() > 0]
    if len(missing_features) > 0:
        print(missing_features)
    else:
        print("æ— ç¼ºå¤±å€¼")

    # å¯¹æ•°å€¼ç‰¹å¾ä½¿ç”¨ä¸­ä½æ•°å¡«å……
    features = features.fillna(features.median())
    target = target.fillna(target.median())

    # 6. æ•°æ®åˆ’åˆ† - ä¿®æ­£ï¼šåˆ’åˆ†ä¸ºè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†
    print("\n5. åˆ’åˆ†æ•°æ®é›†...")
    # é¦–å…ˆåˆ’åˆ†å‡ºæµ‹è¯•é›† (20%)
    X_temp, X_test, y_temp, y_test = train_test_split(
        features, target, test_size=0.2, random_state=42
    )
    
    # ç„¶åä»å‰©ä½™æ•°æ®ä¸­åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›† (64% è®­ç»ƒ, 16% éªŒè¯)
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.2, random_state=42
    )

    print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(X_train)} ({len(X_train)/len(features)*100:.1f}%)")
    print(f"éªŒè¯é›†æ ·æœ¬æ•°: {len(X_val)} ({len(X_val)/len(features)*100:.1f}%)")
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(X_test)} ({len(X_test)/len(features)*100:.1f}%)")

    # 7. æ¨¡å‹è®­ç»ƒ
    print("\n6. è®­ç»ƒæ¨¡å‹...")
    model = train_and_evaluate_model(X_train, X_val, X_test, y_train, y_val, y_test, use_grid_search=use_grid_search)

    # 8. è¯¦ç»†çš„æ¨¡å‹è¯„ä¼°
    print("\n7. æ¨¡å‹è¯„ä¼°...")
    model_results = evaluate_model_performance(model, X_train, X_val, X_test, y_train, y_val, y_test)

    # 9. ç‰¹å¾é‡è¦æ€§åˆ†æ
    print("\n8. ç‰¹å¾é‡è¦æ€§åˆ†æ...")
    importance_df = pd.DataFrame({
        'feature': features.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)

    print("\nç‰¹å¾é‡è¦æ€§æ’å:")
    print(importance_df.head(10))

    # 10. ç»“æœæ€»ç»“
    print("\n=== æœ€ç»ˆç»“æœæ€»ç»“ ===")
    print(f"æœ€ç»ˆæµ‹è¯•é›†RÂ²: {model_results['test']['r2']:.4f}")
    print(f"æœ€ç»ˆæµ‹è¯•é›†RMSE: {model_results['test']['rmse']:.4f}")
    print(f"æœ€é‡è¦çš„5ä¸ªç‰¹å¾: {list(importance_df.head(5)['feature'])}")

    # 11. ç»˜å›¾éƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰
    if enable_plotting:
        print("\n9. ç”Ÿæˆå›¾è¡¨...")
        
        # ç»˜åˆ¶ç›®æ ‡å˜é‡åˆ†å¸ƒ
        print("ç»˜åˆ¶ç›®æ ‡å˜é‡åˆ†å¸ƒ...")
        plot_target_distribution(exploration_data['target_data'], TARGET_VARIABLE)
        
        # ç»˜åˆ¶æ¨¡å‹æ€§èƒ½
        print("ç»˜åˆ¶æ¨¡å‹æ€§èƒ½...")
        plot_model_performance(model_results)
        
        # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
        print("ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§...")
        plot_feature_importance(model, features.columns)
        
        print("æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆå®Œæˆï¼")
    else:
        print("\næ³¨æ„ï¼šç»˜å›¾åŠŸèƒ½å·²ç¦ç”¨ã€‚å¦‚éœ€æŸ¥çœ‹å›¾è¡¨ï¼Œè¯·è®¾ç½® enable_plotting=True")

    # 12. ä¿å­˜æ¨¡å‹å’Œç»“æœï¼ˆæ–°å¢éƒ¨åˆ†ï¼‰
    print("\n10. ä¿å­˜æ¨¡å‹å’Œè®­ç»ƒæ•°æ®...")
    save_info = save_model_and_results(
        model=model,
        results=model_results,
        feature_importance=importance_df,
        exploration_data=exploration_data,
        preprocessor=preprocessor,
        feature_names=features.columns
    )
    
    if save_info:
        print(f"âœ… æ¨¡å‹å’Œæ•°æ®å·²æˆåŠŸä¿å­˜ï¼")
        print(f"ğŸ“‚ ä¿å­˜ä½ç½®: {save_info['save_directory']}")
        print(f"ğŸ•’ æ—¶é—´æˆ³: {save_info['timestamp']}")
    else:
        print("âŒ ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    return {
        'model': model,
        'results': model_results,
        'feature_importance': importance_df,
        'exploration_data': exploration_data,
        'save_info': save_info  # æ–°å¢ä¿å­˜ä¿¡æ¯
    }

if __name__ == "__main__":
    # è¿è¡Œé€‰é¡¹
    results = main(
        enable_plotting=True,      # è®¾ç½®ä¸ºTrueå¯ç”¨ç»˜å›¾
        use_grid_search=True       # è®¾ç½®ä¸ºTrueå¯ç”¨è¶…å‚æ•°è°ƒä¼˜
    )